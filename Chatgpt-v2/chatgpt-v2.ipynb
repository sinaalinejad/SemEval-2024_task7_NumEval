{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -jango (c:\\users\\sina alinejad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -jango (c:\\users\\sina alinejad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tenacity"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -jango (c:\\users\\sina alinejad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -jango (c:\\users\\sina alinejad\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity\n",
      "Successfully installed tenacity-8.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tenacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"./drive/MyDrive/SemEval/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from openai import OpenAI\n",
    "# from tenacity import retry, stop_after_attempt, wait_fixed\n",
    "# %run \"Cleaning.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to fill the blank in the headline\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_fixed(20))\n",
    "def fill_blank(news, masked_headline, prompt, client):\n",
    "    # Construct the prompt by combining the news text and masked headline\n",
    "    prompt = prompt.replace(\"<NEWS>\", news).replace(\"<MASKED HEADLINE\", masked_headline)\n",
    "    messages = []\n",
    "    messages.append(\n",
    "        {\"role\": \"system\", \"content\": \"You are a reasonable and accurate assistant\"}\n",
    "    )\n",
    "    messages.append(\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    )\n",
    "    time.sleep(20)\n",
    "    chat = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "    )\n",
    "    reply = chat.choices[0].message.content\n",
    "    # Extract the generated text from the response and return it\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_id = {\"copy\":0, \"trans\":1, \"paraphrase\":2, \"round\":3, \"subtract\":4, \"add\":5, \"span\":6, \"divide\": 7, \"multiply\":8, \"sround\":9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Dev_Numerical_Reasoning_Cleaned.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_function(row):\n",
    "  cal = row[\"calculation\"]\n",
    "  cal_extract = cal[:cal.index('(')].lower().strip()\n",
    "  cal_id = class_to_id[cal_extract]\n",
    "  return cal_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['calculation_id'] = df.apply(my_function, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0.66, 0.17, 0.07, 0.03, 0.02, 0.01, 0.01, 0.01, 0.01, 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(weights).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.DataFrame()\n",
    "for key, value in class_to_id.items():\n",
    "  op_df = df[df['calculation_id'] == value].sample(n=int(weights[value] * 200), random_state=42)\n",
    "  sample_df = pd.concat([sample_df, op_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the weights for each value in the 'calculation_id' column\n",
    "weights_ = sample_df['calculation_id'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.66\n",
       "1    0.17\n",
       "2    0.07\n",
       "3    0.03\n",
       "4    0.02\n",
       "5    0.01\n",
       "6    0.01\n",
       "7    0.01\n",
       "8    0.01\n",
       "9    0.01\n",
       "Name: calculation_id, dtype: float64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up OpenAI API credentials\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key = config.API_KEY\n",
    ")\n",
    "# The prompt to feed into chatgpt\n",
    "prompt = \"Act as a news expert. I have a text of a news and its masked headline with mask token specified as [MASK]. The mask should be filled with a numerical value. you should just give me the numerical value to put instead of the [MASK].\\nthe news is:\\n<NEWS>\\nthe masked headline is:\\n<MASKED HEADLINE>.\\nyour response should be in format of json with key of ans and value of the numerical answer.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_answer(text: str) -> str:\n",
    "  json.loads(text)['ans']\n",
    "  text = text.replace(\" \",\"\")\n",
    "  match = re.search(r\"<MASK>=([0-9]*[/|\\-|\\\\.]*[0-9]*)\", text)\n",
    "  if match:\n",
    "      number = match.group(1)\n",
    "      return number\n",
    "  match = re.search(r\"([0-9]+)\", text)\n",
    "  if match:\n",
    "    number = match.group(1)\n",
    "    return number\n",
    "  return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_chatgpt(sample, prompt, client, fill_blank, find_answer):\n",
    "  # Fill the blank in the headline for each item in the sample\n",
    "  sample[\"response\"] = sample.apply(\n",
    "      lambda row: fill_blank(row[\"news\"], row[\"masked headline\"], prompt, client), axis=1\n",
    "  )\n",
    "  sample[\"predicted_ans\"] = sample[\"response\"].apply(find_answer)\n",
    "  # Calculate the accuracy of ChatGPT's predictions\n",
    "  accuracy = (sample[\"ans\"] == sample[\"predicted_ans\"]).mean()\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = test_on_chatgpt(sample_df, prompt, client, fill_blank, find_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df[['news', 'masked headline', 'ans', 'predicted_ans', 'calculation', 'response']].to_csv('chatgpt_output_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"chatgpt-v2_output.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (df[\"ans\"] == df[\"predicted_ans\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.775"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
